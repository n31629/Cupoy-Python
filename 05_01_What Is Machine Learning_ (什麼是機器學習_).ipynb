{"cells":[{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"PyYbxuQOC5-y"},"source":["<!--BOOK_INFORMATION-->\n","<img align=\"left\" style=\"padding-right:10px;\" src=\"https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/PDSH-cover-small.png?raw=1\">\n","\n","*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n","\n","*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"ZNOx1tBnC5_D"},"source":["<!--NAVIGATION-->\n","< [Machine Learning](05.00-Machine-Learning.ipynb) | [Contents](Index.ipynb) | [Introducing Scikit-Learn](05.02-Introducing-Scikit-Learn.ipynb) >\n","\n","<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.01-What-Is-Machine-Learning.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"2n6nz2X6C5_H"},"source":["# 什麼是機器學習?"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"a8VYKvFlC5_K"},"source":["機器學習方法於資料科學的應用上，可把機器學習想成是*建構資料的模型*會更有幫助。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"z4yaR19eC5_N"},"source":["## 機器學習的類別\n","\n","機器學習最主要可以分為兩類:監督式學習(supervised learning)和非監督式學習(unsupervised learning)\n","\n","*監督式學習(Supervised learning)*:包含某種方式去塑模(modeling)量測到的資料特徵(feature)以及一些與資料結合的標籤(label)之間的關係。舉例: *分類(classification)*和 *迴歸(regression)*。\n","\n","*非監督式學習(Unsupervised learning)*:包含沒有參考任何標籤的資料集特徵之塑模，它經常被形容成\"讓資料集自己說話\"。舉例: *集群(clustering)*和*維度降低(dimensionality reduction)*\n","\n","*半監督式學習(semi-supervised learning)*:介於監督式學習和非監督式學習之間。半監督式學習在那些資料不具備完整標籤的情況下是非常有用的。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"BWxPS0M6C5_Q"},"source":["## 機器學習應用的質性範例"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"9lx-hiYiC5_U"},"source":["### 分類: 預測離散的標籤"]},{"cell_type":"markdown","source":["先給一組具有標籤的點，希望使用這些點去分類一些未具標籤的點，然後希望使用這些點去分類一些未具標籤的點。"],"metadata":{"id":"uuHehcC4TVi6"}},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"TL_2OJI2C5_X"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-classification-1.png?raw=1)\n"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"mQf5qSb5C5_a"},"source":["有二維的資料，每個點都有兩個特徵在此平面上的(x,y)位置。此外，每一個點都屬於這兩個類別標籤的其中之一，以點的顏色來表示。\n","\n","從這些特徵和標籤，想要建立一個模型，可以決定任一個新的點應該被標示為\"藍色\"還是\"紅色\"。\n","\n","下面舉例用一條簡單的直線為模型來做分類，這個模型的參數則是被資料用來描述那條線位置和方向的特定數字。此模型的參數之最佳值是從這些資料學習來的，這段過程稱為學習。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"sQavd8lYC5_d"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-classification-2.png?raw=1)\n"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"jg4mzYkpC5_f"},"source":["現在此模型已經被訓練好了，可以拿一筆新的資料，用這個模型去預測。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"rxhR6QHDC5_h"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-classification-3.png?raw=1)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"8_CQCTHMC5_k"},"source":["### 回歸:預測連續性的標籤\n","\n","這群資料是由一群資料點所組成，每個點都有一個連續性的標籤。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"5RHE0jTuC5_l"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-regression-1.png?raw=1)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"qPU6PryQC5_m"},"source":["這個分類例子是二維的資料，也就是每個資料點都有兩個特徵描述它，每一個點的顏色代表該點的連續標籤。\n","\n","有許多迴歸模型可用在此種資料型態上，但在此將使用一個簡單的線性迴歸去預測這些點。這個簡單的線性迴歸模型假設把這些資料當作是一個第三度的空間，如此可以擬合一個平面到這些資料中。這是應用一條線擬合到兩個座標資料的問題比較高階的一般化過程。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"DvS9IPGtC5_o"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-regression-2.png?raw=1)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"TDHyKbKxC5_p"},"source":["留意此圖的*feature 1-feature 2*平面，這裡和之前使用的二維圖表是一樣的；然而在此例中，同時使用顏色和三維座標位置來表示這些標籤。從這個視圖，擬合一個平面穿越這些三維資料看起來很合理，它允許我們對任何輸入參數的組合去預測一個預期的標籤。回到二維的投影，當擬合這樣的平面，可以得到下圖的結果。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"toa5EGgBC5_q"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-regression-3.png?raw=1)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"IZvDVSSSC5_r"},"source":["這個擬合的平面提供我們對於一個新的點進行預測所需要的。視覺上，找到的結果如下圖所示。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"YRXAho2rC5_t"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-regression-4.png?raw=1)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"IL-ZK6tPC5_v"},"source":["### 集群:在未建立標籤的資料中推理標籤\n","\n","集群包含的模型描述資料不需要參考到任何已知的標籤。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"eggN6FWFC5_x"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-clustering-1.png?raw=1)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"Mzv3o4WqC5_y"},"source":["從肉眼來看，非常明顯每一個點都是其中一個不同群組的一部份。有這樣的輸入，一個集群的模型將使用這個資料的內部結構去決定哪些點是相關的。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"qA8qwnT5C5_z"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-clustering-2.png?raw=1)\n"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"ZlAT_9QBC5_0"},"source":["### 維度降低: 未標籤資料的結構推理\n","\n","維度降低是非監督學習演算法的另一個例子，它的標籤或其他資訊是從資料集本身的結構推理來的。維度降低可以找出完整資料以某種型式降低為低維度表示時，仍能保有的適切特性。\n","\n","看起來，很明顯的這些資料有一些結構在裡面:在二維平面上，它被畫上一個排列成螺旋狀的一維線條。在某種意義上，這個資料本質上只是一維的，雖然這個一維的資料是被嵌在一個較高維的空間中。在此例中，一個適合的維度降低模型對於這樣的非線性結構會敏感，而且可以被從這低維度表示法中取出。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"s0eCYqo5C5_1"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-dimesionality-1.png?raw=1)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"0W9KJDPdC5_2"},"source":["下圖展示出使用Isomap演算法的視覺化結果，有許多種學習演算法可以執行此工作。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"8ExsW0ziC5_2"},"source":["![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.01-dimesionality-2.png?raw=1)\n"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"Gq6uTazsC5_3"},"source":["留意在此的顏色(在此萃取出的一維潛藏變量)沿著螺旋一致的變化，表示此演算法確實是和眼睛觀察到這個結構。如先前的範例，維度降低演算法的威力在更高維度上會更明顯。例如，假設想要視覺化一個擁有100或1000個特徵值的資料集中的重要關係。視覺化1000個維度的資料是非常挑戰的，而其中一個讓它比較可行的方法就是使用維度降低技巧把資料變成二或三個維度。"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"BItCEKJOC5_3"},"source":["## Summary\n","\n","- *監督式學習(Supervised learning)*:基於已經標上標籤的資料建立模型來預測標籤data\n","  - *分類(Classification)*:建立可以把2個或是更多獨立的類別標上標籤的模型\n","  - *迴歸(Regression)*:建立可以用來預測連續標籤的模型\n","- *非監督式學習(Unsupervised learning)*:建立在未標上標籤的資料中識別出結構的模型\n","  - *集群(Clustering)*:建立在資料中偵測並識別出不同的群組之模型\n","  - *維度降低(Dimensionality reduction)*:建立在比較高維度的資料中可以偵測及識別出較低維度結構的模型。"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"},"colab":{"name":"05_01_What Is Machine Learning? (什麼是機器學習?).ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}